{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9616e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "import string\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_time = 0\n",
    "gamma = 0.99\n",
    "stats = {}  # tracks ewma running average\n",
    "def benchmark(point=None, profile=True): # not thread safe at all\n",
    "    global prev_time\n",
    "    if not profile:\n",
    "        return\n",
    "    if point is not None:\n",
    "        time_taken = time.perf_counter() - prev_time\n",
    "        if point not in stats:\n",
    "            stats[point] = time_taken\n",
    "        stats[point] = stats[point]*gamma + time_taken*(1-gamma)\n",
    "        print(f\"took {time_taken} to reach {point}, ewma={stats[point]}\")\n",
    "    prev_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a14c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorDatasetGenerator(Dataset):\n",
    "    def __init__(self, **kwargs):\n",
    "        # define default values for parameters, can override any using kwargs\n",
    "        # noise parameters\n",
    "        self.num_noise = (50, 70)  # number of locations to generate noise at\n",
    "        self.noise_size = (5, 10)  # size that each noise instance can be\n",
    "        \n",
    "        # image parameters\n",
    "        self.size = 256 # shape of image\n",
    "        self.channels = 1  # default is greyscale\n",
    "        \n",
    "        # target parameters\n",
    "        self.color_classifier = None  # function that maps colors to classes (supports iterables)\n",
    "        self.num_classes = 2  # how many possible classes there are\n",
    "        self.color_range = (50, 200)  # range of values that the color-to-be-classified can be\n",
    "        self.radius = (self.size//6, self.size//3)  # range of possible radii for circles\n",
    "        self.num_objects = 1 # for multiclass problems, if we want to classify multiple things\n",
    "        \n",
    "        # actual dataset\n",
    "        self.num_images = 10   # totally arbitrary\n",
    "        self.options = []  # list of dataset options that need to be saved\n",
    "        for k,v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "            self.options.append(k)\n",
    "    \n",
    "    def add_target(self, arr):\n",
    "        num_objects = self.num_objects # np.random.randint(*self.num_objects)\n",
    "        color = np.random.randint(*self.color_range, (num_objects, self.channels)) # rgb for now\n",
    "        \n",
    "        label = np.zeros((self.num_classes))\n",
    "        label[self.color_classifier(color)] = 1  # multi-hot encoded\n",
    "\n",
    "        # probably should make sure they dont overlap too much, but num_objects=1 for now\n",
    "        radii = np.random.randint(*self.radius, (num_objects))  \n",
    "        locations = np.random.randint(self.radius[1], self.size-self.radius[1], (num_objects, 2))\n",
    "        for radius, location in zip(radii, locations):\n",
    "            x_coords = np.arange(radius)\n",
    "            for x in x_coords:\n",
    "                height = 2*int(np.sqrt(radius**2 - x**2))\n",
    "                y_coords = np.arange(height) - height//2 + location[1]\n",
    "                arr[location[0]+x, y_coords] = color\n",
    "                arr[location[0]-x, y_coords] = color\n",
    "        return label\n",
    "\n",
    "    def add_noise(self, arr):\n",
    "        num_noise = np.random.randint(*self.num_noise)\n",
    "        sizes = np.random.randint(*self.noise_size, num_noise)\n",
    "        colors = np.random.randint(1, 255, (num_noise, self.channels))\n",
    "        locations = np.random.randint(self.noise_size[1], self.size-self.noise_size[1], (num_noise, 2))\n",
    "        for size, color, location in zip(sizes, colors, locations):\n",
    "            arr[location[0]:location[0]+size,location[1]:location[1]+size] = color\n",
    "    \n",
    "    def generate_one(self, profile=False):\n",
    "        benchmark(profile=profile)\n",
    "        img = np.zeros((self.size, self.size, self.channels))\n",
    "        benchmark(\"initialization\", profile)\n",
    "        label = self.add_target(img)\n",
    "        benchmark(\"circle\", profile)\n",
    "        self.add_noise(img)\n",
    "        benchmark(\"noise\", profile)\n",
    "        return img, label\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.num_images\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        print(idx)\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        np.random.seed(idx)  # to make results repeatable\n",
    "        image, label = self.generate_one()\n",
    "        sample = {'image': image, 'label': label, \"idx\": idx}\n",
    "        if hasattr(self, \"transform\"):\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85513ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_classifier(color):\n",
    "    if color >= 150:  # valid colors (for now) for the circle is [100, 200], split in the middle\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1a1bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dataset = ColorDatasetGenerator(color_classifier=color_classifier)\n",
    "color_dataloader = DataLoader(color_dataset, batch_size=4, shuffle=True, \n",
    "                              num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a90976",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(color_dataset[5][\"image\"], cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
