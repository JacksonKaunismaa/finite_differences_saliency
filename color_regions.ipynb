{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557037fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "import colorsys\n",
    "import imageio\n",
    "import scipy.ndimage \n",
    "import os\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49f70f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_time = 0\n",
    "gamma = 0.99\n",
    "stats = {}  # tracks ewma running average\n",
    "def benchmark(point=None, profile=True): # not thread safe at all\n",
    "    global prev_time\n",
    "    if not profile:\n",
    "        return\n",
    "    if point is not None:\n",
    "        time_taken = time.perf_counter() - prev_time\n",
    "        if point not in stats:\n",
    "            stats[point] = time_taken\n",
    "        stats[point] = stats[point]*gamma + time_taken*(1-gamma)\n",
    "        print(f\"took {time_taken} to reach {point}, ewma={stats[point]}\")\n",
    "    prev_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorDatasetGenerator(Dataset):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        # define default values for parameters, can override any using kwargs\n",
    "        # noise parameters\n",
    "        self.num_noise = (50, 70)  # number of locations to generate noise at\n",
    "        self.noise_size = (5, 10)  # size that each noise instance can be\n",
    "\n",
    "        # image parameters\n",
    "        self.size = 256 # shape of image\n",
    "        self.channels = 1  # default is greyscale\n",
    "        self.bg_color = 0  # must have same number of channels \n",
    "\n",
    "        # target parameters\n",
    "        self.color_classifier = None  # function that maps colors to classes (supports iterables)\n",
    "        self.num_classes = 2  # how many possible classes there are\n",
    "        # greyscale\n",
    "        self.color_range = (50, 200)  # range of values that the greyscale color-to-be-classified can be\n",
    "        # RGB (which we generate as HSV for simplicity)\n",
    "        self.value_range = (20, 100) # range for value in HSV (subset of (0, 100))\n",
    "        self.saturation_range = (20, 100) # range for saturation in HSV (subset of (0, 100))\n",
    "        self.hue_range = (0, 360)  # range for hue in HSV (subset of (0, 360))\n",
    "    \n",
    "        self.radius = (self.size//6, self.size//3)  # range of possible radii for circles\n",
    "        self.num_objects = 1 # supports ranges, if want multiclass\n",
    "\n",
    "        # actual dataset\n",
    "        #self.labels = {}  # {filename: label} mapping\n",
    "        self.image_indices = (0, 1_000_00)   # range of np.random.seeds for the given dataset\n",
    "        self.options = []  # list of dataset options that need to be saved\n",
    "        # self.save_dir = \"\"   # location for all images to be stored\n",
    "        for k,v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "            self.options.append(k)\n",
    "    \n",
    "    def iterative_color_cvt(self, conversion, iterable):\n",
    "        # iterates over first dimension\n",
    "        convert_func = getattr(colorsys, conversion)\n",
    "        return np.array(list(map(lambda x: convert_func(*x), iterable)))\n",
    "        \n",
    "    def generate_colors(self, amt):\n",
    "        if self.channels == 1: # greyscale\n",
    "            color = np.random.randint(*self.color_range, (amt))\n",
    "        else:  # rgb\n",
    "            hue = np.random.randint(*self.hue_range, (amt))/360\n",
    "            saturation = np.random.randint(*self.saturation_range, (amt))/100\n",
    "            value = np.random.randint(*self.value_range, (amt))/100\n",
    "            color = (self.iterative_color_cvt(\"hsv_to_rgb\", zip(hue, saturation, value))*255.).round() #(np.array(list(map(lambda x: colorsys.hsv_to_rgb(*x), zip(hue, saturation, value))))*255).round()\n",
    "        return color\n",
    "\n",
    "    def add_target(self, arr, set_color):\n",
    "        num_objects = self.num_objects # np.random.randint(*self.num_objects)\n",
    "        \n",
    "        if set_color is not None:\n",
    "            colors = np.array([set_color]*num_objects)\n",
    "        else:\n",
    "            colors = self.generate_colors(num_objects)\n",
    "\n",
    "        label = np.zeros((self.num_classes))\n",
    "        label[self.color_classifier(colors)] = 1  # multi-hot encoded\n",
    "        if self.num_classes == 2:\n",
    "            label = np.expand_dims(label[0], 0)\n",
    "\n",
    "        # probably should make sure they dont overlap too much, but num_objects=1 for now\n",
    "        radii = np.random.randint(*self.radius, (num_objects))\n",
    "        locations = np.random.randint(self.radius[1], self.size-self.radius[1], (num_objects, 2))\n",
    "        for radius, location, color in zip(radii, locations, colors):\n",
    "            x_coords = np.arange(radius)\n",
    "            for x in x_coords:\n",
    "                height = 2*int(np.sqrt(radius**2 - x**2))\n",
    "                y_coords = np.arange(height) - height//2 + location[1]\n",
    "                arr[location[0]+x, y_coords] = color\n",
    "                arr[location[0]-x, y_coords] = color\n",
    "        return label, colors, radii, locations  # doesnt really work if we are doing multiclass\n",
    "\n",
    "    def add_noise(self, arr):\n",
    "        num_noise = np.random.randint(*self.num_noise)\n",
    "        sizes = np.random.randint(*self.noise_size, num_noise)\n",
    "        colors = self.generate_colors(num_noise)\n",
    "        locations = np.random.randint(self.noise_size[1], self.size-self.noise_size[1], (num_noise, 2))\n",
    "        for size, color, location in zip(sizes, colors, locations):\n",
    "            arr[location[0]:location[0]+size,location[1]:location[1]+size] = color\n",
    "\n",
    "    def generate_one(self, set_color=None):\n",
    "        img = np.ones((self.size, self.size, self.channels)) * self.bg_color\n",
    "        label, color, size, pos = self.add_target(img, set_color)\n",
    "        self.add_noise(img)\n",
    "        return img, label, color, size, pos\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_indices[1] - self.image_indices[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        np.random.seed(idx)  # to make results repeatable\n",
    "        image, label, color, _, __ = self.generate_one()\n",
    "        if hasattr(self, \"transform\"):\n",
    "            image = self.transform(image)\n",
    "        sample = {'image': image, 'label': label, 'color': color}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d23390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextureDatasetGenerator(Dataset):\n",
    "    def __init__(self, dtd_loc, **kwargs):\n",
    "        super().__init__()\n",
    "        # define default values for parameters, can override any using kwargs\n",
    "        # noise parameters\n",
    "        self.num_noise = (50, 70)  # number of locations to generate noise at\n",
    "        self.noise_size = (5, 10)  # size that each noise instance can be\n",
    "#         self.value_range = (20, 100) # range for value in HSV (subset of (0, 100))\n",
    "#         self.saturation_range = (20, 100) # range for saturation in HSV (subset of (0, 100))\n",
    "#         self.hue_range = (0, 360)  # range for hue in HSV (subset of (0, 360))\n",
    "\n",
    "        # image parameters\n",
    "        self.size = 128 # shape of image\n",
    "        self.channels = 3  # default is greyscale\n",
    "        self.bg_color = 0  # must have same number of channels \n",
    "\n",
    "        # target parameters\n",
    "        self.num_classes = 2  # how many possible classes there are\n",
    "        self.textures = []  # list of texture images (order matters)\n",
    "        self.texture_labels = []  # list of class idxes that each texture is in\n",
    "        self.texture_file_names = []  # list of filename associated to each texture\n",
    "        self.texname_to_idx = {}  # maps texture types to their class indices\n",
    "        self.idx_to_texname = {}  # maps class indices to texture types\n",
    "    \n",
    "        self.radius_frac = (1./6, 1./3)  # range of possible radii (fraction of self.size)\n",
    "        self.num_objects = 1 # supports ranges, if want multiclass\n",
    "\n",
    "        # actual dataset\n",
    "        #self.labels = {}  # {filename: label} mapping\n",
    "        self.image_indices = (0, 1_000_00)   # range of np.random.seeds for the given dataset\n",
    "        self.options = []  # list of dataset options that need to be saved\n",
    "        # self.save_dir = \"\"   # location for all images to be stored\n",
    "        for k,v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "            self.options.append(k)\n",
    "        \n",
    "        self.load_dtd_textures(os.path.join(dtd_loc, \"images\"), \n",
    "                               os.path.join(dtd_loc, \"labels\", \"labels_joint_anno.txt\"))\n",
    "            \n",
    "    def load_dtd_textures(self, images_path, labels_file):\n",
    "        with open(labels_file, \"r\") as f:\n",
    "            labels = f.readlines()\n",
    "        for label in tqdm(labels):\n",
    "            name, *categ = label.split()\n",
    "            if len(categ) > 1: # some textures are multi-class, ignore these for now\n",
    "                continue\n",
    "            if categ[0] not in self.texname_to_idx:\n",
    "                self.texname_to_idx[categ[0]] = len(self.texname_to_idx)\n",
    "            imread = imageio.v2.imread(os.path.join(images_path, name))\n",
    "            \n",
    "            downsampled = scipy.ndimage.zoom(imread, \n",
    "                                              [self.size/imread.shape[0], self.size/imread.shape[1], 1.], \n",
    "                                              order=1)\n",
    "            self.textures.append(downsampled)\n",
    "            self.texture_file_names.append(name)\n",
    "            self.texture_labels.append(self.texname_to_idx[categ[0]])\n",
    "\n",
    "        self.idx_to_texname = {y:x for x,y in self.texname_to_idx.items()}\n",
    "        # self.textures = np.asarray(self.textures) # images have different shapes\n",
    "        self.texture_labels = np.asarray(self.texture_labels)\n",
    "        self.num_classes = len(self.texname_to_idx)\n",
    "        \n",
    "    @property\n",
    "    def radius(self):\n",
    "        return int(self.radius_frac[0]*self.size), int(self.radius_frac[1]*self.size)\n",
    "           \n",
    "    def add_target(self, arr, num_objects, textures):\n",
    "        \n",
    "        # pick a random texture image\n",
    "        # pick a random location to sample that image at (since our image size is smaller than the texture image size)\n",
    "        #sample_locs_x = np.random.randint(self.textures[textures[0]].shape[0]-self.size, size=num_objects)\n",
    "        #sample_locs_y = np.random.randint(self.textures[textures[0]].shape[1]-self.size, size=num_objects)\n",
    "        label = np.zeros((self.num_classes))\n",
    "        label[self.texture_labels[textures[0]]] = 1  # multi-hot encoded\n",
    "        if self.num_classes == 2:\n",
    "            label = np.expand_dims(label[0], 0)\n",
    "\n",
    "        # probably should make sure they dont overlap too much, but num_objects=1 for now\n",
    "        radii = np.random.randint(*self.radius, (num_objects))\n",
    "        locations = np.random.randint(self.radius[1], self.size-self.radius[1], (num_objects, 2))\n",
    "        target_zip = zip(radii, locations, textures)#, sample_locs_x, sample_locs_y)\n",
    "        for radius, location, texture in target_zip:#, sample_loc_x, sample_loc_y in target_zip:\n",
    "            x_coords = np.arange(radius)\n",
    "            # subsampling of image guaranteed to be at least size x size\n",
    "            tex_image = self.textures[texture]#[sample_loc_x:, sample_loc_y:, :]\n",
    "            for x in x_coords:\n",
    "                height = 2*int(np.sqrt(radius**2 - x**2))\n",
    "                y_coords = np.arange(height) - height//2 + location[1]\n",
    "                arr[location[0]+x, y_coords] = tex_image[location[0]+x, y_coords]\n",
    "                arr[location[0]-x, y_coords] = tex_image[location[0]-x, y_coords]\n",
    "        return label, radii, locations  # doesnt really work if we are doing multiclass\n",
    "        \n",
    "    def generate_colors(self, amt):\n",
    "        return np.random.randint(0,255, size=(amt,3))\n",
    "    \n",
    "    def add_noise(self, arr):\n",
    "        num_noise = np.random.randint(*self.num_noise)\n",
    "        sizes = np.random.randint(*self.noise_size, num_noise)\n",
    "        colors = self.generate_colors(num_noise)\n",
    "        locations = np.random.randint(self.noise_size[1], self.size-self.noise_size[1], (num_noise, 2))\n",
    "        for size, color, location in zip(sizes, colors, locations):\n",
    "            arr[location[0]:location[0]+size,location[1]:location[1]+size] = color\n",
    "\n",
    "    def generate_one(self):\n",
    "        num_objects = self.num_objects # np.random.randint(*self.num_objects)\n",
    "        tex_indices = np.random.randint(len(self.textures), size=num_objects)\n",
    "        bg_image = np.random.randint(len(self.textures))\n",
    "        while self.texture_labels[tex_indices[0]] == self.texture_labels[bg_image]:\n",
    "            bg_image = np.random.randint(len(self.textures))\n",
    "        img = self.textures[bg_image].copy() #np.ones((self.size, self.size, self.channels)).astype(np.float32) * self.bg_color\n",
    "        label, size, pos = self.add_target(img, num_objects, tex_indices)\n",
    "        \n",
    "        self.add_noise(img)\n",
    "        return img, label, tex_indices, size, pos\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_indices[1] - self.image_indices[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        np.random.seed(idx)  # to make results repeatable\n",
    "        image, label, *_ = self.generate_one()\n",
    "        if hasattr(self, \"transform\"):\n",
    "            image = self.transform(image)\n",
    "        sample = {'image': image, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_classifier(color):\n",
    "    if colorsys.rgb_to_hsv(*(color[0]/255))[0] >= 150:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22469059",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dataset = ColorDatasetGenerator(color_classifier=color_classifier,\n",
    "                                     channels=3,\n",
    "                                     bg_color=np.array([127., 127., 127.]))\n",
    "color_dataloader = DataLoader(color_dataset, batch_size=4, shuffle=True, \n",
    "                              num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a13534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(color_dataset[535][\"image\"]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a189f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(color_dataset[5][\"image\"], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f3030",
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_dataset = TextureDatasetGenerator(\"./data/dtd\",\n",
    "                                    channels=3,\n",
    "                                    bg_color=np.array([127., 127., 127.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b884b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(151701)\n",
    "sample_img, sample_lbl, tex_idx, *_ = tex_dataset.generate_one()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(sample_img/255.)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(tex_dataset.textures[int(tex_idx)].astype(np.float32)/255.)\n",
    "print(tex_dataset.idx_to_texname[sample_lbl.argmax()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
