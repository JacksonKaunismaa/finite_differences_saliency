{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a90d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boiler plate code from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "transform = transforms.Compose( # dont really want to normalize here\n",
    "     [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 32\n",
    "num_valid = 5000\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "valid, test = torch.utils.data.random_split(testset, [num_valid, 10000-num_valid], \n",
    "                                            generator=torch.Generator(device=\"cuda\").manual_seed(4))\n",
    "testloader = torch.utils.data.DataLoader(torch.utils.data.Subset(testset, valid.indices),\n",
    "                                         batch_size=batch_size, shuffle=False)\n",
    "validloader = torch.utils.data.DataLoader(torch.utils.data.Subset(testset, test.indices), \n",
    "                                         batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f184848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicResNet(nn.Module):\n",
    "    def __init__(self, conv_layers, num_classes, img_shape, groups=1):\n",
    "        super().__init__()\n",
    "        self.conv_layers1 = []  # entry into residual block \n",
    "        self.conv_layers2 = []  # https://arxiv.org/pdf/1512.03385.pdf Figure 3\n",
    "        self.batch_norms1 = []\n",
    "        self.batch_norms2 = []\n",
    "        self.is_resid = []\n",
    "        channels = img_shape[-1]\n",
    "        img_size = img_shape[0]\n",
    "        for l in conv_layers:  # (out_channels, kernel_size, stride) is each l\n",
    "            if l[2] == 2: # stride\n",
    "                pad_type = \"valid\"\n",
    "                img_size = (img_size-l[1])//l[2] + 1 # https://arxiv.org/pdf/1603.07285.pdf\n",
    "            else:\n",
    "                pad_type = \"same\"\n",
    "            if isinstance(l[0], float):\n",
    "                l[0] = int(l[0])\n",
    "                l[0] -= l[0] % groups # ensure divisble by groups\n",
    "            self.is_resid.append(l[2] == 1 and channels == l[0])\n",
    "            self.conv_layers1.append(nn.Conv2d(channels, l[0], l[1], stride=l[2], padding=pad_type, groups=groups))\n",
    "            channels = l[0]\n",
    "            self.final_num_logits = channels * img_size * img_size \n",
    "            self.batch_norms1.append(nn.BatchNorm2d(channels))\n",
    "            self.batch_norms2.append(nn.BatchNorm2d(channels))\n",
    "            self.conv_layers2.append(nn.Conv2d(channels, channels, l[1], padding=pad_type, groups=groups))\n",
    "        self.conv_layers1 = nn.ModuleList(self.conv_layers1)\n",
    "        self.conv_layers2 = nn.ModuleList(self.conv_layers1)\n",
    "        self.batch_norms1 = nn.ModuleList(self.batch_norms1)\n",
    "        self.batch_norms2 = nn.ModuleList(self.batch_norms2)\n",
    "\n",
    "        self.fully_connected1 = nn.Linear(self.final_num_logits, 1000)\n",
    "        self.fully_connected2 = nn.Linear(1000, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        network_iter = zip(self.conv_layers1, self.conv_layers2, self.batch_norms1, self.batch_norms2, self.is_resid)\n",
    "        for conv1, conv2, batch_norm1, batch_norm2, is_resid in network_iter:\n",
    "            x_conv1 = F.relu(batch_norm1(conv1(x)))\n",
    "            x_conv2 = F.relu(batch_norm2(conv2(x)))\n",
    "            if is_resid:\n",
    "                x = x + x_conv2  # residual block\n",
    "            else:\n",
    "                x = x_conv2  # dimension increasing block\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fully_connected1(x))\n",
    "        x = self.fully_connected2(x)\n",
    "        return x    \n",
    "\n",
    "    def num_params(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "    \n",
    "    def save_model_state_dict(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "    \n",
    "    def load_model_state_dict(self, path):\n",
    "        self.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444b8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_num(pred_logits, labels):\n",
    "    pred_probabilities = F.softmax(pred_logits)\n",
    "    classifications = torch.argmax(pred_probabilities, 1)\n",
    "    correct = (labels == classifications).sum()\n",
    "    return correct\n",
    "\n",
    "def train(net, optimizer, loss, epochs):\n",
    "    va_losses = []\n",
    "    tr_losses = []\n",
    "    va_accuracies = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_tr_loss = 0.0\n",
    "        for i, (imgs, labels) in tqdm(enumerate(trainloader)):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(imgs)\n",
    "            batch_loss = loss(outputs, labels)\n",
    "            epoch_tr_loss += batch_loss.item()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_va_loss = 0.0\n",
    "        epoch_va_correct = 0\n",
    "        for i, (imgs, labels) in enumerate(validloader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = net(imgs)\n",
    "            epoch_va_loss += loss(outputs, labels).item()\n",
    "            epoch_va_correct += correct_num(outputs, labels).item()\n",
    "        epoch_va_accuracy = epoch_va_correct/num_valid\n",
    "        print(f'Epoch {epoch + 1}: va_loss: {epoch_va_loss}, va_accuracy: {epoch_va_accuracy}, tr_loss: {epoch_tr_loss}')\n",
    "        va_losses.append(epoch_va_loss)\n",
    "        tr_losses.append(epoch_tr_loss)\n",
    "        va_accuracies.append(epoch_va_accuracy)\n",
    "    return va_losses, va_accuracies, tr_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee70d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_res_net = BasicResNet([[64, 7, 1],  # num_channels (input and output), kernel_size, stride\n",
    "                             [64, 3, 1],\n",
    "                             [128, 3, 1],\n",
    "                             [128, 3, 1],\n",
    "                             [128, 3, 2],\n",
    "                             [128, 3, 2],\n",
    "                             [256, 3, 1],\n",
    "                             [256, 3, 1],\n",
    "                             [256, 3, 1],\n",
    "                             [256, 3, 1],\n",
    "                             [512, 3, 1],\n",
    "                             [512, 3, 1],\n",
    "                             [512, 3, 2]], 10, [32, 32, 3])\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(basic_res_net.parameters())\n",
    "print(basic_res_net.num_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b8ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train(basic_res_net, optim, loss_func, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf750b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_scale = np.sqrt(3)\n",
    "color_cnn = BasicResNet([[64*w_scale, 7, 1],  \n",
    "                         [64*w_scale, 3, 1], # num_channels (input and output), kernel_size, stride\n",
    "                         [128*w_scale, 3, 1],\n",
    "                         [128*w_scale, 3, 1],\n",
    "                         [128*w_scale, 3, 2],\n",
    "                         [128*w_scale, 3, 2],\n",
    "                         [256*w_scale, 3, 1],\n",
    "                         [256*w_scale, 3, 1],\n",
    "                         [256*w_scale, 3, 1],\n",
    "                         [256*w_scale, 3, 1],\n",
    "                         [512*w_scale, 3, 1],\n",
    "                         [512*w_scale, 3, 1],\n",
    "                         [512*w_scale, 3, 2]], 10, [32, 32, 3], groups=3)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(color_cnn.parameters())\n",
    "print(color_cnn.num_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db511277",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train(color_cnn, optim, loss_func, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf297fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_cnn.save_model_state_dict(\"cifar10_colorcnn.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17373a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_img = valid.dataset.data[55]\n",
    "print(valid.dataset.targets[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a42bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def finite_differences(model, target_class, stacked_img, locations, color):\n",
    "    num_iters = 40 # sample 8 values randomly\n",
    "    baseline_activations = model(torch.tensor(stacked_img))[:, target_class]\n",
    "    largest_slope = np.zeros(stacked_img.shape[0])  # directional finite difference?\n",
    "    slices = np.index_exp[np.arange(64), color, locations[:, 0], locations[:, 1]]\n",
    "    for i in range(num_iters):\n",
    "        diff = np.random.randint(-20, 20, (stacked_img.shape[0]))*2 + 1\n",
    "        img = stacked_img.copy()\n",
    "        img[slices] = np.clip(img[slices] + diff, 0, 255)\n",
    "        actual_diffs = img[slices] - stacked_img[slices]  # due to clipping, need to recalculate\n",
    "        img_norm = ((img - img.mean()) / img.std() * 0.5) + 0.5  # normalize\n",
    "        activations = model(torch.tensor(img_norm))[:, target_class]\n",
    "        activation_diff = (activations - baseline_activations).cpu().numpy()\n",
    "        finite_difference = np.clip(activation_diff/actual_diffs, -30, 30) # take absolute slope\n",
    "        largest_slope = np.where(abs(finite_difference) > abs(largest_slope), finite_difference, largest_slope)\n",
    "    return largest_slope\n",
    "        \n",
    "\n",
    "def finite_differences_map(model, target_class, img):\n",
    "    # generate a saliency map using finite differences method (iterate over colors)\n",
    "    model.eval()\n",
    "    batch_size = 64  # check 64 pixel positions in parallel\n",
    "    im_size = img.shape[0]\n",
    "    img = img.astype(np.float32)/255. # pixels in range [0, 1]\n",
    "    values_x = np.repeat(np.arange(im_size), im_size)\n",
    "    values_y = np.tile(np.arange(im_size), im_size)\n",
    "    indices = np.stack((values_x, values_y), axis=1)\n",
    "    stacked_img = np.repeat(np.expand_dims(img, 0), batch_size, axis=0)\n",
    "    stacked_img = np.transpose(stacked_img, (0, 3, 1, 2)) # NCHW format\n",
    "    img_heat_map = np.zeros((im_size, im_size, 3)) \n",
    "    for color in range(3):\n",
    "        for k in tqdm(range(0, im_size*im_size, batch_size)):\n",
    "            actual_batch_size = min(batch_size, im_size*im_size-k+batch_size)\n",
    "            locations = indices[k:k+batch_size]\n",
    "            largest_slopes = finite_differences(model, target_class, stacked_img, locations, color)\n",
    "            img_heat_map[locations[:,0], locations[:,1], color] = largest_slopes\n",
    "    return img_heat_map.sum(axis=2)  # linear approximation aggregation?\n",
    "heat_map = finite_differences_map(color_cnn, 8, explain_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e7bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(heat_map.max(), heat_map.min(), heat_map.mean(), heat_map.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dca1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(heat_map, cmap=\"bwr\", interpolation=\"bilinear\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab5f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(explain_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map_basic = finite_differences_map(basic_res_net, 8, explain_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2eda07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(heat_map_basic, cmap=\"bwr\", interpolation=\"bilinear\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f9b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 10\n",
    "random_images = np.random.choice(5000, (num_images), replace=False)\n",
    "plt.figure(figsize=(8, 5*num_images))\n",
    "for i, r in enumerate(random_images):\n",
    "    target_class = valid.dataset.targets[r]\n",
    "    explain_random_img = valid.dataset.data[r]\n",
    "    random_heat_map = finite_differences_map(color_cnn, target_class, explain_random_img)\n",
    "    plt.subplot(num_images, 2, 2*i+1)\n",
    "    plt.imshow(explain_random_img)\n",
    "    plt.subplot(num_images, 2, 2*i+2)\n",
    "    plt.imshow(random_heat_map, cmap=\"bwr\", interpolation=\"bilinear\")\n",
    "    plt.colorbar()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
