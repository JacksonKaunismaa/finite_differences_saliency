{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f59161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "import color_regions, network, visualizations, utils\n",
    "from color_regions import *\n",
    "from network import *\n",
    "from visualizations import *\n",
    "from utils import *\n",
    "from hooks import *\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7625d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up autoreloading of shared code\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport color_regions,network,visualizations,utils,hooks\n",
    "%aimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "prev_time = 0\n",
    "gamma = 0.99\n",
    "stats = {}  # tracks ewma running average\n",
    "def benchmark(point=None, profile=True, verbose=True, cuda=True): # not thread safe at all\n",
    "    global prev_time\n",
    "    if not profile:\n",
    "        return\n",
    "    if cuda:\n",
    "        torch.cuda.synchronize()\n",
    "    time_now = time.perf_counter()\n",
    "    if point is not None:\n",
    "        point = f\"{sys._getframe().f_back.f_code.co_name}-{point}\"\n",
    "        time_taken = time_now - prev_time\n",
    "        if point not in stats:\n",
    "            stats[point] = time_taken\n",
    "        stats[point] = stats[point]*gamma + time_taken*(1-gamma)\n",
    "        if verbose:\n",
    "            print(f\"took {time_taken} to reach {point}, ewma={stats[point]}\")\n",
    "    prev_time = time_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_set = TextureDatasetGenerator(\"./data/dtd\")  # -> do this so we only load once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4eadc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "     [transforms.ToTensor(),\n",
    "      transforms.RandomRotation(90)])\n",
    "\n",
    "batch_size = 128  # seems to be the fastest batch size\n",
    "train_indices = (0, 500_000) # size of training set\n",
    "valid_indices = (1_250_000, 1_260_000)\n",
    "test_indices = (2_260_000, 2_270_000)\n",
    "\n",
    "def set_loader_helper(indices):\n",
    "    data_set = TextureDatasetGenerator(main_data_set,\n",
    "                                       transform=transform,\n",
    "                                       noise_size=(5,15),\n",
    "                                       size=128,\n",
    "                                       radius_frac=(1/3, 1/2.1),\n",
    "                                       image_indices=indices)\n",
    "    loader = torch.utils.data.DataLoader(data_set, batch_size=batch_size, \n",
    "                                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "    return data_set, loader\n",
    "train_set, train_loader = set_loader_helper(train_indices)\n",
    "valid_set, valid_loader = set_loader_helper(valid_indices)\n",
    "test_set, test_loader = set_loader_helper(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f349501",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net = ResNet([[32, 7, 2],  # num_channels (input and output), kernel_size, stride\n",
    "                  [64, 3, 1],\n",
    "                  [64, 3, 1],\n",
    "                  [128, 3, 2],\n",
    "                  [128, 3, 1],\n",
    "                  [128, 3, 1],\n",
    "                  [256, 3, 2],\n",
    "                  [256, 3, 1],\n",
    "                  [512, 3, 2],\n",
    "                  [512, 3, 1]], valid_set.num_classes, [128, 128, 3], \n",
    "                   \"texture_net.dict\", fc_layers=[160]).to(device)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(res_net.parameters())\n",
    "print(res_net.num_params())\n",
    "res_net.load_model_state_dict(optim=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train(res_net, optim, loss_func, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc44053",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(500_001)\n",
    "explain_img, explain_target_logit, *__ = valid_set.generate_one()\n",
    "heat_map = finite_differences_map(res_net, valid_set, explain_target_logit.argmax(), explain_img, device=device, batch_size=127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(explain_img/255.)\n",
    "plt.subplot(1, 2, 2)\n",
    "imshow_centered_colorbar(heat_map.sum(axis=2), cmap=\"bwr\", title=\"FD Map\")\n",
    "print(valid_set.idx_to_texname[explain_target_logit.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8303659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_scales = [3,5,7,9,13,15]\n",
    "if 1: \n",
    "    %store -r pca_directions_1_stride pca_directions_s_stride\n",
    "else:\n",
    "    pca_directions_1_stride = find_pca_directions(valid_set, 16384, default_scales, 1)\n",
    "    # s_stride not used for pca_map calculations, just for visualizing better what the \n",
    "    # PCA directions end up looking like (technically they are slightly different from\n",
    "    # just accessing 1_stride in a strided manner, since they were computed with different\n",
    "    # samples (though they are very close due to large sample size)\n",
    "    pca_directions_s_stride = find_pca_directions(valid_set, 16384, default_scales, default_scales)\n",
    "    %store pca_directions_1_stride pca_directions_s_stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa30368",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(pca_directions_1_stride, \"Strides=1\", default_scales, lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60033135",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(pca_directions_s_stride, \"Strides=scales\", default_scales, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fc123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(500_001)\n",
    "explain_img, explain_target_logit, *__ = valid_set.generate_one()\n",
    "result = pca_direction_grids(res_net, valid_set, explain_target_logit.argmax(), explain_img, default_scales, \n",
    "                    pca_directions_s_stride, device=device, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pca direction of above cell visualization\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(explain_img.squeeze())\n",
    "for c in range(3):\n",
    "    plt.subplot(1,4,c+2)\n",
    "    imshow_centered_colorbar(result[...,c], cmap=\"bwr\", title=f\"Channel {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9508fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [1_2123, 1_40_124, 1_508_559, 1_5_019_258, 1_2_429_852, 9032, 5832, 12, 5014, 92, 42, 52, \n",
    "         52_934, 935_152, 1_000_000, 1_000_001, 27, 24, 512, 999_105]  # 20 \n",
    "# def generate_many_pca(net, seeds, pca_directions_1_stride, scales, dataset, \n",
    "#         component=0, batch_size=128, strides=None, skip_1_stride=False, device=None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f023ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_map_s_strides, pca_map_1_strides, grad_maps, explain_imgs = generate_many_pca(res_net, component=0, strided_scales=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd60ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "guided_net = GuidedBackprop(res_net)\n",
    "guided_pca_map_s_strides, guided_pca_map_1_strides, guided_grad_maps, explain_imgs = generate_many_pca(guided_net, component=0, strided_scales=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_grid_figure([explain_imgs, guided_pca_map_s_strides, guided_pca_map_1_strides, guided_grad_maps, pca_map_s_strides, pca_map_1_strides, grad_maps], \n",
    "                transpose=True, \n",
    "                titles=[\"Image\", \"Guided Strides=3\", \"Guided strides=1\", \"Guided Gradient\", \"Strides=3\", \"strides=1\", \"Gradient\"], \n",
    "                channel_mode=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6475bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_grid_figure([explain_imgs, guided_pca_map_s_strides, guided_pca_map_1_strides, guided_grad_maps, pca_map_s_strides, pca_map_1_strides, grad_maps], \n",
    "                transpose=True, \n",
    "                titles=[\"Image\", \"Guided Strides=3\", \"Guided strides=1\", \"Guided Gradient\", \"Strides=3\", \"strides=1\", \"Gradient\"], \n",
    "                channel_mode=\"collapse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[abs(guided_pca_map_s_strides[i] - guided_pca_map_1_strides[i]).max() for i in range(len(guided_pca_map_1_strides))]\n",
    "# no major changes really? Can eliminate channels, can do strides=3 for 9x speedup\n",
    "# little cost to quality (and speeds up pca calculations)\n",
    "# for component = 0\n",
    "\n",
    "# add to overleaf (uoft email one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346defc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_grid_figure([explain_imgs, guided_pca_map_s_strides, guided_pca_map_1_strides, guided_grad_maps, pca_map_s_strides, pca_map_1_strides, grad_maps], \n",
    "                transpose=True, \n",
    "                titles=[\"Image\", \"Guided Strides=3\", \"Guided strides=1\", \"Guided Gradient\", \"Strides=3\", \"strides=1\", \"Gradient\"], \n",
    "                channel_mode=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e789a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets do the same but for component=1\n",
    "pca_map_s_strides, pca_map_1_strides, grad_maps, explain_imgs = generate_many_pca(res_net, component=1, strided_scales=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84539e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets do the same but for component=1\n",
    "guided_net = GuidedBackprop(res_net)\n",
    "guided_pca_map_s_strides, guided_pca_map_1_strides, guided_grad_maps, explain_imgs = generate_many_pca(guided_net, component=1, strided_scales=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4004f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_grid_figure([explain_imgs, guided_pca_map_s_strides, guided_pca_map_1_strides, guided_grad_maps, pca_map_s_strides, pca_map_1_strides, grad_maps], \n",
    "                transpose=True, \n",
    "                titles=[\"Image\", \"Guided Strides=3\", \"Guided strides=1\", \"Guided Gradient\", \"Strides=3\", \"strides=1\", \"Gradient\"], \n",
    "                channel_mode=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74069258",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_grid_figure([explain_imgs, guided_pca_map_s_strides, guided_pca_map_1_strides, guided_grad_maps, pca_map_s_strides, pca_map_1_strides, grad_maps], \n",
    "                transpose=True, \n",
    "                titles=[\"Image\", \"Guided Strides=3\", \"Guided strides=1\", \"Guided Gradient\", \"Strides=3\", \"strides=1\", \"Gradient\"], \n",
    "                channel_mode=\"collapse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec65324",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_grid_figure([explain_imgs, guided_pca_map_s_strides, guided_pca_map_1_strides, guided_grad_maps, pca_map_s_strides, pca_map_1_strides, grad_maps], \n",
    "                transpose=True, \n",
    "                titles=[\"Image\", \"Guided Strides=3\", \"Guided strides=1\", \"Guided Gradient\", \"Strides=3\", \"strides=1\", \"Gradient\"], \n",
    "                channel_mode=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[abs(guided_pca_map_s_strides[i] - guided_pca_map_1_strides[i]).max() for i in range(len(guided_pca_map_1_strides))]\n",
    "# no major changes really? Can eliminate channels, can do strides=3 for 9x speedup\n",
    "# little cost to quality (and speeds up pca calculations)\n",
    "# for component = 1 (largest diff is in same location, idx 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f717bf",
   "metadata": {},
   "source": [
    "# PCA Direction convergence experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e6036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_scales = [3,5,7,9,13,15]\n",
    "small_pca_directions_1_stride = find_pca_directions(valid_set, 512, default_scales, 1)\n",
    "small_pca_directions_s_stride = find_pca_directions(valid_set, 512, default_scales, default_scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(510)\n",
    "test_directions = find_pca_directions(valid_set, 8192*4, default_scales, default_scales, component=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(small_pca_directions_1_stride, \"Strides=1\", default_scales)\n",
    "# component 0\n",
    "# small sample (512)\n",
    "# to get not all 1s: generate images with PCA, see if recoverable\n",
    "# should be fourier basis (test on natural images?)\n",
    "\n",
    "# do sanity checks next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2588126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(pca_directions_1_stride, \"Strides=1\", default_scales)\n",
    "# component 0\n",
    "# large sample (2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(small_pca_directions_s_stride, \"Strides=scales\", default_scales)\n",
    "# component 0\n",
    "# small sample (512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c39a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(pca_directions_s_stride, \"Strides=scales\", default_scales)\n",
    "# component 0\n",
    "# large sample (2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9981afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(test_directions, \"Strides=scales\", default_scales) \n",
    "# component 0\n",
    "# seed 510 gargantuan (32768) sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e6101",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(test_directions, \"Strides=scales\", default_scales)\n",
    "# component 1\n",
    "# seed 508, small sample (512)\n",
    "\n",
    "# unlikely to be diff from guided backprop since its already basically edge detector (comp 1)\n",
    "# advantage of PCA method is that it can take into accont more than just the pixel\n",
    "# unit of attribution isnt just a pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c954c967",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(test_directions, \"Strides=scales\", default_scales) \n",
    "# component 1\n",
    "# seed 507, small sample (512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3653a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(test_directions, \"Strides=scales\", default_scales) \n",
    "# component 1\n",
    "# seed 507, large (2048) sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f76dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(test_directions, \"Strides=scales\", default_scales) \n",
    "# component 1\n",
    "# seed 508, large (2048) sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c966780",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(test_directions, \"Strides=scales\", default_scales)\n",
    "# component 1\n",
    "# seed 507, huge (8192) sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfcf3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(test_directions, \"Strides=scales\", default_scales)\n",
    "# component 1\n",
    "# seed 507 gargantuan (32768) sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772f5f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(test_directions, \"Strides=scales\", default_scales)\n",
    "# component 1\n",
    "# seed 510 gargantuan (32768) sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f8060b",
   "metadata": {},
   "source": [
    "What if we run the same experiment, but cheat with a prior on pixel values that we know *should* be informative to the output logit, namely values closest to the decision boundary?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f86a46e",
   "metadata": {},
   "source": [
    "# Model Optimization Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net.save_model_state_dict(optim=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    res_net.forward(generated_img, profile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd852210",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = sum(stats.values())  # --> gave 3x speed! (Fast and Accurate Model scaling?)\n",
    "for k,v in stats.items():    # --> the 3x speedup caused underfitting though, so switched to 2x\n",
    "    print(k,(100.*v/total))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
