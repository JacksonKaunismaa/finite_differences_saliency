{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f59161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "import color_regions, network, visualizations, utils\n",
    "from color_regions import *\n",
    "from network import *\n",
    "from visualizations import *\n",
    "from utils import *\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7625d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up autoreloading of shared code\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport color_regions,network,visualizations,utils\n",
    "%aimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "prev_time = 0\n",
    "gamma = 0.99\n",
    "stats = {}  # tracks ewma running average\n",
    "def benchmark(point=None, profile=True, verbose=True, cuda=True): # not thread safe at all\n",
    "    global prev_time\n",
    "    if not profile:\n",
    "        return\n",
    "    if cuda:\n",
    "        torch.cuda.synchronize()\n",
    "    time_now = time.perf_counter()\n",
    "    if point is not None:\n",
    "        point = f\"{sys._getframe().f_back.f_code.co_name}-{point}\"\n",
    "        time_taken = time_now - prev_time\n",
    "        if point not in stats:\n",
    "            stats[point] = time_taken\n",
    "        stats[point] = stats[point]*gamma + time_taken*(1-gamma)\n",
    "        if verbose:\n",
    "            print(f\"took {time_taken} to reach {point}, ewma={stats[point]}\")\n",
    "    prev_time = time_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_set = TextureDatasetGenerator(\"./data/dtd\")  # -> do this so we only load once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4eadc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "     [transforms.ToTensor(),\n",
    "      transforms.RandomRotation(90)])\n",
    "\n",
    "batch_size = 128  # seems to be the fastest batch size\n",
    "train_indices = (0, 500_000) # size of training set\n",
    "valid_indices = (1_250_000, 1_260_000)\n",
    "test_indices = (2_260_000, 2_270_000)\n",
    "\n",
    "def set_loader_helper(indices):\n",
    "    data_set = TextureDatasetGenerator(main_data_set,\n",
    "                                       transform=transform,\n",
    "                                       noise_size=(5,15),\n",
    "                                       size=128,\n",
    "                                       radius_frac=(1/3, 1/2.1),\n",
    "                                       image_indices=indices)\n",
    "    loader = torch.utils.data.DataLoader(data_set, batch_size=batch_size, \n",
    "                                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "    return data_set, loader\n",
    "train_set, train_loader = set_loader_helper(train_indices)\n",
    "valid_set, valid_loader = set_loader_helper(valid_indices)\n",
    "test_set, test_loader = set_loader_helper(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f349501",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net = ResNet([[32, 7, 2],  # num_channels (input and output), kernel_size, stride\n",
    "                  [64, 3, 1],\n",
    "                  [64, 3, 1],\n",
    "                  [128, 3, 2],\n",
    "                  [128, 3, 1],\n",
    "                  [128, 3, 1],\n",
    "                  [256, 3, 2],\n",
    "                  [256, 3, 1],\n",
    "                  [512, 3, 2],\n",
    "                  [512, 3, 1]], valid_set.num_classes, [128, 128, 3], \n",
    "                   \"texture_net.dict\", fc_layers=[160]).to(device)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(res_net.parameters())\n",
    "print(res_net.num_params())\n",
    "res_net.load_model_state_dict(optim=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train(res_net, optim, loss_func, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc44053",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(500_001)\n",
    "explain_img, explain_target_logit, *__ = valid_set.generate_one()\n",
    "heat_map = finite_differences_map(res_net, valid_set, explain_target_logit.argmax(), explain_img, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e797e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(heat_map).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(explain_img/255.)\n",
    "plt.subplot(1, 2, 2)\n",
    "imshow_centered_colorbar(heat_map, cmap=\"bwr\", title=\"FD Map\")\n",
    "print(explain_target_logit)\n",
    "# do 3 maps for each color channel, and also maybe do absolute values (might cancel each other)\n",
    "# MAYBE DO CUBES OF COLOR CLASS, AND ALSO VISULAZIE WITH POINT CLOUD THE NETWORK LOGIT (CAN ONLY DO 1 CLASS, OR MAYBE DO MULTIPLE MAPS)\n",
    "# probably better for getting step-function style stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8303659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_scales = [3,5,7,9,13,15]\n",
    "pca_directions_1_stride = find_pca_directions(valid_set, 1024, default_scales, 1, sample_size=2048)\n",
    "pca_directions_s_stride = find_pca_directions(valid_set, 1024, default_scales, default_scales, sample_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2588126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6*4, 12))\n",
    "for i, res in enumerate(pca_directions_s_stride):\n",
    "    compressed_results = np.concatenate(np.concatenate(res, 1), 1)\n",
    "    plt.subplot(1,len(pca_directions_s_stride),i+1)\n",
    "    if i == 0:\n",
    "        plt.title(\"Strided windows\")\n",
    "    plt.imshow(compressed_results, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6*4, 12))\n",
    "for i, res in enumerate(pca_directions_1_stride):\n",
    "    compressed_results = np.concatenate(np.concatenate(res, 1), 1)\n",
    "    plt.subplot(1,len(pca_directions_1_stride),i+1)\n",
    "    if i == 0:\n",
    "        plt.title(\"Stride=1\")\n",
    "    plt.imshow(compressed_results, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f8060b",
   "metadata": {},
   "source": [
    "What if we run the same experiment, but cheat with a prior on pixel values that we know *should* be informative to the output logit, namely values closest to the decision boundary?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f86a46e",
   "metadata": {},
   "source": [
    "# Model Optimization Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net.save_model_state_dict(optim=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    res_net.forward(generated_img, profile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd852210",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = sum(stats.values())  # --> gave 3x speed! (Fast and Accurate Model scaling?)\n",
    "for k,v in stats.items():    # --> the 3x speedup caused underfitting though, so switched to 2x\n",
    "    print(k,(100.*v/total))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
