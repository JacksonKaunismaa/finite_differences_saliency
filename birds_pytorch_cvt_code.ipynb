{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorviz.birds_dataset.data import ImageDataset\n",
    "from colorviz.conv_color.config_objects import ImageDatasetCfg\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchinfo\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from collections import Counter\n",
    "\n",
    "from colorviz.conv_color.visualizations import *\n",
    "from colorviz.birds_dataset.data import *\n",
    "from colorviz.conv_color.config_objects import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"bird_data/EfficientNetB0-525-(224 X 224)- 98.97.h5\", custom_objects={'F1_score':'F1_score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1).cuda(0)\n",
    "net.eval()\n",
    "transform = EfficientNet_B0_Weights.IMAGENET1K_V1.transforms()\n",
    "data_cfg = ImageDatasetCfg(batch_size=64,\n",
    "                            num_workers=4,\n",
    "                            data_dir=\"/scratch/ssd004/datasets/imagenette2/320\",\n",
    "                            device=\"cuda:0\")\n",
    "\n",
    "dsets = {split: ImageDataset(split, transform, data_cfg) for split in [\"train\", \"val\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    full_preds = torch.empty(0).cuda()\n",
    "    full_labels = torch.empty(0).cuda()\n",
    "    for b in dsets['val'].dataloader():\n",
    "        preds = net(b['image'].cuda(0))\n",
    "        full_preds = torch.concat([full_preds, preds.argmax(-1)])\n",
    "        full_labels = torch.concat([full_labels, b['label'].cuda()])\n",
    "    full_labels = full_labels.detach().cpu().numpy().astype(np.int32)\n",
    "    full_preds = full_preds.detach().cpu().numpy().astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(zip(full_labels, full_preds))\n",
    "inferred_lbls = {lbl:max(counts.items(), key=lambda x: x[1] if x[0][0]==lbl else -9)[0][1]for lbl in range(10)}\n",
    "remapped_labels = np.asarray([inferred_lbls[lbl] for lbl in full_labels])\n",
    "inferred_lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(remapped_labels == full_preds).mean()  # => input transformation is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(net, input_size=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[8].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_layers = list(net.modules())\n",
    "keras_layers = model.layers\n",
    "\n",
    "for i, keras_layer in enumerate(keras_layers):    \n",
    "    if hasattr(keras_layer, 'weights'):\n",
    "        keras_weights = keras_layer.get_weights()\n",
    "        if not keras_weights:\n",
    "            continue\n",
    "        keras_weights = [np.transpose(w) for w in keras_weights]  # Transpose weights for compatibility\n",
    "        # print(keras_layer)\n",
    "        # Find matching PyTorch layer based on size\n",
    "        for pytorch_layer in pytorch_layers:\n",
    "            if isinstance(pytorch_layer, (nn.Conv2d, nn.Linear)):\n",
    "                pytorch_weights = pytorch_layer.weight.data\n",
    "                if pytorch_weights.size() == keras_weights[0].shape:\n",
    "                    pytorch_layer.weight.data = torch.from_numpy(keras_weights[0])\n",
    "                    if len(keras_weights) > 1:\n",
    "                        pytorch_layer.bias.data = torch.from_numpy(keras_weights[1])\n",
    "                    break\n",
    "            elif isinstance(pytorch_layer, nn.BatchNorm2d):\n",
    "                pytorch_weights = pytorch_layer.weight.data\n",
    "                if pytorch_weights.size() == keras_weights[0].shape:\n",
    "                    pytorch_layer.weight.data = torch.from_numpy(keras_weights[0])\n",
    "                    pytorch_layer.bias.data = torch.from_numpy(keras_weights[1])\n",
    "                    pytorch_layer.running_mean = torch.from_numpy(keras_weights[2])\n",
    "                    pytorch_layer.running_var = torch.from_numpy(keras_weights[3])\n",
    "                    break\n",
    "        else:\n",
    "            print(\"Failed to find Pytorch match on \", keras_layer, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[4].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_conversion = {\"kernel\": \"weight\", \n",
    "                   \"moving_mean\": \"running_mean\",\n",
    "                   \"moving_variance\": \"running_variance\",\n",
    "                   \"gamma\": \"weight\",\n",
    "                   \"beta\": \"bias\",\n",
    "                   \"depthwise_kernel\": \"weight\",\n",
    "                   \"bias\": \"bias\"\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = set()\n",
    "n_params = net.named_parameters()\n",
    "for layer in model.layers:\n",
    "    for k,v in layer.__dict__.items():\n",
    "        if isinstance(v, tf.Variable):\n",
    "            print(k, v.shape)\n",
    "            all_names.add(k)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,p in net.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[20].kernel.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"without_f1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[19].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compiled_metrics._metrics_in_order = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"without_f1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {split: ImageDataset(split, ImageDatasetCfg(data_dir=\"bird_data\", device=\"cuda\")) for split in [\"train\", \"valid\", \"test\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = tf.keras.utils.image_dataset_from_directory(\"bird_data/train\", \n",
    "                                                         image_size=(224,224),\n",
    "                                                         batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = np.concatenate([s[0].numpy() for s, i in zip(train_dset, range(16384//16))]).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_scales = [3,5,7,9,13,15]\n",
    "pca_dirs = find_pca_directions(train_dset, 8192, default_scales, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"bird_data/big_sample_pca_dirs.pkl\", \"wb\") as p:\n",
    "    pickle.dump(pca_dirs, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"bird_data/pca_dirs.pkl\", \"wb\") as p:\n",
    "    pickle.dump(pca_dirs, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(pca_dirs, \"test\", default_scales, lines=False)  # sample size 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(pca_dirs, \"test\", default_scales, lines=False)  # sample size 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca_directions(pca_dirs, \"test\", default_scales, lines=False)  # sample size 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "tr_transform = transforms.Compose([transforms.Resize(256, antialias=True),\n",
    "                                transforms.RandomCrop(224),\n",
    "                                #transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],   # ???\n",
    "                                                        std=[0.229, 0.224, 0.225]),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomRotation(8.),\n",
    "                                transforms.ColorJitter(contrast=0.1)\n",
    "                                                        ])\n",
    "\n",
    "\n",
    "# load_model_state_dict(net, optim=opt, sched=combined_sched)\n",
    "\n",
    "\n",
    "va_transform = EfficientNet_B0_Weights.IMAGENET1K_V1.transforms()\n",
    "transform_map = dict(train=tr_transform,\n",
    "                        valid=va_transform,\n",
    "                        test=va_transform)\n",
    "\n",
    "\n",
    "data_cfg = ImageDatasetCfg(batch_size=3,\n",
    "                            num_workers=4,\n",
    "                            data_dir=\"/scratch/ssd004/scratch/jackk/birds_data\",\n",
    "                            device=\"cuda:0\")\n",
    "\n",
    "\n",
    "dsets = {split: ImageDataset(split, transform_map[split], data_cfg, False) for split in [\"train\", \"valid\", \"test\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets['train'].class_name_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dsets['valid'].class_name_to_idx.items():\n",
    "    if dsets['train'].class_name_to_idx[k] != v:\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets['train'].class_name_to_idx == dsets['valid'].class_name_to_idx "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipyflow)",
   "language": "python",
   "name": "ipyflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
